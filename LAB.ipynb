{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77f2c78e",
   "metadata": {},
   "source": [
    "# Phase 1: Setup, Data Loading, Initial Exploration & Train/Val/Test Split\n",
    "\n",
    "## Objective\n",
    "Predict whether an online shopping session leads to a purchase (binary classification)  \n",
    "**Dataset**: [UCI Online Shoppers Purchasing Intention](https://archive.ics.uci.edu/dataset/468/online+shoppers+purchasing+intention+dataset)\n",
    "\n",
    "### Pipeline Order (No Data Leakage)\n",
    "1. Load raw data & quick inspection  \n",
    "2. **Split into Train (70%) / Validation (15%) / Test (15%)**  \n",
    "3. Then preprocessing is fitted on Train only (Phase 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da12674",
   "metadata": {},
   "source": [
    "## 1.1 — Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444a0ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Core Libraries ──\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings, time, os, sys\n",
    "\n",
    "# ── Sklearn ──\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, f1_score,\n",
    "    precision_score, recall_score, accuracy_score, roc_auc_score\n",
    ")\n",
    "\n",
    "# ── Deep Learning ──\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# ── Settings ──\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "\n",
    "print(\"✅ All libraries imported successfully\")\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"PyTorch {torch.__version__}\")\n",
    "print(f\"Random seed fixed at {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4397f1",
   "metadata": {},
   "source": [
    "## 1.2 — Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5219e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download from UCI repository\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "online_shoppers = fetch_ucirepo(id=468)\n",
    "df = online_shoppers.data.original.copy()\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Target column: 'Revenue'\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48acc61d",
   "metadata": {},
   "source": [
    "## 1.3 — Initial Raw Data Inspection\n",
    "Quick look at types, missing values, and class distribution **before any transformation**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c6710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Data types & missing values ──\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA TYPES & MISSING VALUES\")\n",
    "print(\"=\" * 60)\n",
    "info_df = pd.DataFrame({\n",
    "    \"dtype\": df.dtypes,\n",
    "    \"non_null\": df.count(),\n",
    "    \"null_count\": df.isnull().sum(),\n",
    "    \"null_%\": (df.isnull().sum() / len(df) * 100).round(2)\n",
    "})\n",
    "print(info_df)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"BASIC STATISTICS (Numerical)\")\n",
    "print(\"=\" * 60)\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daabab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Class distribution (target: Revenue) ──\n",
    "print(\"CLASS DISTRIBUTION\")\n",
    "print(\"=\" * 40)\n",
    "class_counts = df[\"Revenue\"].value_counts()\n",
    "class_pct = df[\"Revenue\"].value_counts(normalize=True) * 100\n",
    "print(pd.DataFrame({\"count\": class_counts, \"percentage\": class_pct.round(2)}))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "sns.countplot(x=\"Revenue\", data=df, palette=\"viridis\", ax=ax)\n",
    "ax.set_title(\"Target Distribution — Class Imbalance Check\")\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height())} ({p.get_height()/len(df)*100:.1f}%)',\n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='bottom', fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n⚠️  Imbalance ratio: ~{class_counts.iloc[0]/class_counts.iloc[1]:.1f}:1 (negative:positive)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67232af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Identify column types ──\n",
    "categorical_cols = df.select_dtypes(include=[\"object\", \"bool\"]).columns.tolist()\n",
    "numerical_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "\n",
    "# Remove target from feature lists\n",
    "if \"Revenue\" in categorical_cols:\n",
    "    categorical_cols.remove(\"Revenue\")\n",
    "if \"Revenue\" in numerical_cols:\n",
    "    numerical_cols.remove(\"Revenue\")\n",
    "\n",
    "print(f\"Categorical features ({len(categorical_cols)}): {categorical_cols}\")\n",
    "print(f\"Numerical features  ({len(numerical_cols)}): {numerical_cols}\")\n",
    "print(f\"Target: Revenue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a0ddae",
   "metadata": {},
   "source": [
    "## 1.4 — Train / Validation / Test Split (BEFORE Preprocessing)\n",
    "\n",
    "**Critical**: We split the raw data first to prevent any data leakage.  \n",
    "- **Train**: 70% — used to fit preprocessing & train models  \n",
    "- **Validation**: 15% — used for hyperparameter tuning & model selection  \n",
    "- **Test**: 15% — used **once** for final evaluation only  \n",
    "\n",
    "We use **stratified** splitting to preserve class proportions across all sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0021d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Separate features and target ──\n",
    "X = df.drop(columns=[\"Revenue\"])\n",
    "y = df[\"Revenue\"].astype(int)  # Ensure binary int (0/1)\n",
    "\n",
    "# ── Step 1: Split into Train (70%) and Temp (30%) ──\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.30,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# ── Step 2: Split Temp into Validation (15%) and Test (15%) ──\n",
    "# 50% of 30% = 15% each\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.50,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=y_temp\n",
    ")\n",
    "\n",
    "# ── Verify split sizes and class proportions ──\n",
    "print(\"=\" * 60)\n",
    "print(\"SPLIT SUMMARY (Raw data, NO preprocessing applied yet)\")\n",
    "print(\"=\" * 60)\n",
    "for name, X_set, y_set in [(\"Train\", X_train, y_train),\n",
    "                             (\"Validation\", X_val, y_val),\n",
    "                             (\"Test\", X_test, y_test)]:\n",
    "    pos_rate = y_set.mean() * 100\n",
    "    print(f\"  {name:12s}: {X_set.shape[0]:5d} samples ({X_set.shape[0]/len(df)*100:.1f}%) | \"\n",
    "          f\"Positive class: {pos_rate:.1f}%\")\n",
    "\n",
    "print(f\"\\n  Total: {len(X_train)+len(X_val)+len(X_test)} samples\")\n",
    "print(f\"  Original: {len(df)} samples\")\n",
    "print(\"\\n✅ Split done BEFORE any preprocessing — no data leakage.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2245a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Visual check: class proportion preserved across splits ──\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "for ax, (name, y_set) in zip(axes, [(\"Train\", y_train), (\"Validation\", y_val), (\"Test\", y_test)]):\n",
    "    counts = y_set.value_counts()\n",
    "    ax.bar([\"No Purchase (0)\", \"Purchase (1)\"], counts.values, color=[\"#3498db\", \"#e74c3c\"])\n",
    "    ax.set_title(f\"{name} Set (n={len(y_set)})\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    for i, v in enumerate(counts.values):\n",
    "        ax.text(i, v + 5, f\"{v}\\n({v/len(y_set)*100:.1f}%)\", ha=\"center\", fontsize=10)\n",
    "\n",
    "plt.suptitle(\"Stratified Split Verification — Class Proportions\", fontsize=13, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Phase 1 Complete — Data loaded, inspected, and split.\")\n",
    "print(\"   Preprocessing will be fitted on TRAIN set only in Phase 2.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
